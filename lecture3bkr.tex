\documentclass[10pt]{article}
% Include statements
\usepackage{graphicx}
\usepackage{amsfonts,amssymb,amsmath,amsthm}
\usepackage[sort]{natbib}
\usepackage[margin=1in,nohead]{geometry}
\usepackage{multirow,rotating,array}
\usepackage{algorithm,algorithmic}
\usepackage{pdfsync}
\usepackage{hyperref}
\hypersetup{backref,colorlinks=true,citecolor=blue,linkcolor=blue,urlcolor=blue}
\renewcommand{\qedsymbol}{$\blacksquare$}
\setlength{\parindent}{0cm}
\setlength{\parskip}{10pt}


% For sequential numbering
\newcounter{lecnum}
\renewcommand{\thepage}{\thelecnum\ -\ \arabic{page}}
\renewcommand{\thesection}{\thelecnum.\arabic{section}}
\renewcommand{\theequation}{\thelecnum.\arabic{equation}}
\renewcommand{\thefigure}{\thelecnum.\arabic{figure}}
\renewcommand{\thetable}{\thelecnum.\arabic{table}}



% Theorem environments (\autoref compatible)
\usepackage{aliascnt}
\newtheorem{theorem}{Theorem}[lecnum]

\newaliascnt{result}{theorem}
\newtheorem{result}[theorem]{Result}
\aliascntresetthe{result}
\providecommand*{\resultautorefname}{Result}
\newaliascnt{lemma}{theorem}
\newtheorem{lemma}[lemma]{Lemma}
\aliascntresetthe{lemma}
\providecommand*{\lemmaautorefname}{Lemma}
\newaliascnt{prop}{theorem}
\newtheorem{proposition}[prop]{Proposition}
\aliascntresetthe{prop}
\providecommand*{\propautorefname}{Proposition}
\newaliascnt{cor}{theorem}
\newtheorem{corollary}[cor]{Corollary}
\aliascntresetthe{cor}
\providecommand*{\corautorefname}{Corollary}
\newaliascnt{conj}{theorem}
\newtheorem{conjecture}[conj]{Conjecture}
\aliascntresetthe{conj}
\providecommand*{\conjautorefname}{Corollary}
\newaliascnt{def}{theorem}
\newtheorem{definition}[def]{Definition}
\aliascntresetthe{def}
\providecommand*{\defautorefname}{Definition}
\newaliascnt{ex}{theorem}
\newtheorem{example}[ex]{Example}
\aliascntresetthe{ex}
\providecommand*{\exautorefname}{Example}


\newtheorem{assumption}{Assumption}
\renewcommand{\theassumption}{\Alph{assumption}}
\providecommand*{\assumptionautorefname}{Assumption}

\def\algorithmautorefname{Algorithm}
\renewcommand*{\figureautorefname}{Figure}%
\renewcommand*{\tableautorefname}{Table}%
\renewcommand*{\partautorefname}{Part}%
\renewcommand*{\chapterautorefname}{Chapter}%
\renewcommand*{\sectionautorefname}{Section}%
\renewcommand*{\subsectionautorefname}{Section}%
\renewcommand*{\subsubsectionautorefname}{Section}% 


% My Macros
\def\indep{\perp\!\!\!\perp}
\newcommand{\given}{\mbox{ }\vert\mbox{ }}
\newcommand{\F}{\mathcal{F}}
\newcommand{\Expect}[1]{\mathbb{E}\!\left[#1\right]}
\renewcommand{\P}{\mathbb{P}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\B}{\mathcal{B}}
\DeclareMathOperator*{\Variance}{Var}
\newcommand{\Var}[1]{\Variance\!\left[#1\right]}
\DeclareMathOperator*{\Covariance}{Cov}
\newcommand{\Cov}[1]{\Covariance\!\left[#1\right]}
\newcommand{\Y}{\mathcal{Y}}
\newcommand{\norm}[1]{\left\lVert #1 \right\rVert}
\newcommand{\email}[1]{\href{mailto:#1}{#1}}
\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\newcommand{\indicator}{\mathbbm{1}}
\newcommand{\cdist}{\rightsquigarrow}
\newcommand{\cprob}{\xrightarrow{P}}
\newcommand{\clp}{\xrightarrow{L_p}}
\newcommand{\cas}{\xrightarrow{as}}
\renewcommand{\bar}{\overline}
\renewcommand{\hat}{\widehat}


% Your new macros



% To be entered
\setcounter{lecnum}{0}
\newcommand{\lecturer}{Prof.\ McDonald}
\newcommand{\scribe}{Prof.\ McDonald}
\newcommand{\chtitle}{Scribe template}
\newcommand{\lecdate}{7 August 2017}


\begin{document}
\rule{6.5in}{1pt}

\textsc{STAT--S 782
        \hfill \thelecnum\ --- \chtitle
        \hfill \lecdate}

\textsc{Lecturer: \lecturer \hfill Scribe: \scribe}
\rule{6.5in}{1pt}

\section{convex optimization}
min_x f(x) \st g_i(x)\leq 0, Ax=b

FOC
\convex prob w/ diff'le f
a feasible x is optimal \iff \nabla f(x)^T(y-x)\geq 0\forall feasible y

if unconstrained, reduces to \nabla f(x)=0

\begin{example}
min_x 0.5x^TQx+b^Tx+c, Q semiposdef
FOC: \nabla f(x)=Qx+b=0
\begin{cases}
  Q strict posdef \then x^*=-Q^{}-1}b (strict convexity) \\
    Q singular, b\notin col(Q) \then no sol; min f = -\infty\\
    Q singular, b\in col(Q) \then x^*=-Q^+b+z, z\in null(Q)
\end{cases}
\end{example}

\begin{example}
  proj onto convex c
  min_x||a-x||_2^2 \st x\in C
  FOC: \nabla f(x)^T(y-x) = (x-a)^T(y-x)\geq 0 \forall y\in C
  \iff a-x\in normal cone \N_C(x)
\end{example}

\section{Useful Operations}
partial optimization
h(x) = min_{y\in C} f(x,y) is convex if f is convex, C is convex
\begin{example}
  min_{x_1,x_2} f(x), g1(x1)\leq0, g2(x2)\leq0 convex \then min_x1 h(x1) \st g1(x1)\leq0 is convex

  transformations h:\R\to\R monotone inc
  f(x) convex \then h(f(x)) convex
\end{example}

{change of vars}
\begin{example}
  min_x f(x)=\sum_{k=1}^p\gamma_k x_1^{a_{k_1}}\cdots x_n^{a_{k_n}} (posynomial)
  C\st ineq are same form, eq affine
  non-convex y_i=log x_i
  min_y log(\sum_{k=1}^{p_0}exp{a_0k^Ty+b_0k}
  \st log(\sum_{i=1}^{m}exp{a_ik^Ty+b_ik}\leq 0, c_j^Ty+d_j=0, j=1,...,r
  is convex

\section*{Eliminate equality constraints}
min_xf(x) \st g_i(x)\leq 0, Ax=b

x feasible,thenx=My+x_0\st Ax_0=b, col(M)=null(A)

so prob equiv to min_yf(My+x_0) \st g_i(My+x_0)\leq 0 (gets rid of equality constraints

more common: slack vars (esp in SVMs)
min_{x,s}f(x) \st s\geq0, g_i(x)+s_i=0, Ax=b (not convex unless g_i affine)

relax nonaffine constraints
min_{x\in C} f(x) \then min_{x\in\~{C}}f(x) C\subseteq\~{C} (optimum is smaller or equal)

\section*{standard problems}
\subsection*{LP}
min_x c^Tx \st affine ineq \& affine eq constraints
Dantzig's simplex alg or interior point methods

\begin{example}[Basis Pursuit]
  min_\beta ||\beta||_0 \st X\beta=y (nonconvex)

  relax to   min_\beta ||\beta||_1 \st X\beta=y
  and reformulate as min_{\beta,z}1^Tz \st z\geq\beta,z\geq-\beta,x\beta=y
\end{example}

\begin{example}[Dantzig selector]
  min_\beta||\beta||_1 \st ||X^T(y-X\beta)||_\infty\leq\lambda
\end{example}

  
\subsection*{QP}
obj fn is quad
ex: lasso, ridge regression, OLS, portfolio optimization

\subsection*{Semi-Definite Program}
LP over matrices instead of vectors
Let X\cdot A\equiv tr(X^TA)
min_{X\in S_n} tr(C^TX) \st tr*A_i^TX)=b_i, X semiposdef

\subsection*{Conic program}
\begin{example}
  min_x C^Tx \st Ax=b, D(x)+d\in closed convex cone K

  summary:
  LP\subset QP\subset SOCP\subset SDP\subset CP
  (cvx package in MATLAB/python/R)
  


\section*{Lower bound in LP}
want B\leq min_x f(x)

min_{x,y}px+qy\st x+y\geq2,x\geq0,y\geq0
transform:
ax+ay\geq 2a if a\geq0
bx\geq0 if b\geq0
cy\geq0 if c\geq0
\then (a+b)x+(a+c)y\geq2a
\then B=2a if p,q\geq0

what's the best lb?
max_{a,b,c} 2a \st a+b=p, a+c=q, a,b,c\geq0 (dual problem)

# of dual vars = # primal constraints

min_x,y px+qy \st x\geq0, y\leq1, 3x+y=2
\to ax\geq0, -by\geq-b, 3cx+cy=2c, a,b\geq0

combine: (a+3c)x+(-b+c)y\geq2c-b,
max_a,b,c 2c-b \st a+3c=p, -b+c=q, a,b\geq0

in general


This document provides some information for creating the scribe files
for STAT--S 682. Before you begin, please read through the macros and
commands above. You should change all the {\tt to be entered} commands
as appropriate. Then, simply begin your notes in this document. 

The first thing to note is that there are a number of
macros which I have already defined. You should use these as much as
possible. These include macros for $\R$, $\Expect{}$, $\Var{}$, and
many others. Whenever you find yourself needing these symbols, please
use the macros.

Second, please place your newly defined macros in the appropriate
location in the header.

Theorems, definitions, conjectures, corollaries, etc have already been
created using \AmS-\LaTeX.

All displayed equations should be numbered for further reference. 

A few notes about references: try to use the \verb|\autoref| rather
that \verb|\ref|. That way you can type \\ \verb|\autoref{thm:whatever}|
to get \autoref{thm:convergence-1} rather than writing \verb|Theorem \ref{thm:whatever}| 
to get Theorem \ref{thm:convergence-1}. 

Finally, please use \textsc{Bib}\TeX to create references. Simply add
new references to the {\tt .bib} file in the repo. Also, I recommend
using the {\tt natbib} package which gives, for instance,
\citep{Vapnik1998} or~\citet{Vapnik1998} rather than~\cite{Vapnik1998}

The rest of this document is an example from an old course. Note
especially~\autoref{alg:kalman}.

\section{Random variables}


A {\em random variable} is a map $X$ from a probability space $\Omega$ to $\R$. We write
\begin{equation}
  P(X\in A)=P(\{\omega\in\Omega : X(\omega)\in A\})\label{eq:1}
\end{equation}
and we write $X \sim P$ to mean that $X$ has distribution $P$. 

The {\em cumulative distribution function} (cdf) of $X$ is
\begin{equation}
  F_X(x) = F(x) = P(X \leq x).\label{eq:2}
\end{equation}
If $X$ is discrete, its probability mass function (pmf) is
\begin{equation}
p_X(x) = p(x) = P(X = x).\label{eq:3}
\end{equation}
If $X$ is continuous, then its probability density function function (pdf) satisfies
\begin{equation}
P(X \in A) = \int_A p_X(x)dx = \int_A p(x)dx\label{eq:4}
\end{equation}
and $p_X(x) = p(x) = F'(x)$. The following are all equivalent:
\begin{align}
  X&\sim P,& X&\sim F, & X&\sim p, & \mathcal{L}(X)&=P.
\end{align}

Suppose that $X \sim P$ and $Y \sim Q$. We say that $X$ and $Y$ have
the same distribution if
\begin{equation}
  P(X\in A)=Q(Y \in A)\label{eq:5}
\end{equation}
for all $A$. In other words, $P = Q$. In that case we say that $X$ and
$Y$ are equal in distribution and we write $X \overset{d}{=} Y$ or
$\mathcal{L}(X) = \mathcal{L}(Y)$ . It can be shown that $X
\overset{d}{=} Y$ if and only if 
$F_X(t) = F_Y (t)$ for all $t$.

\section{Expected values}
\label{sec:expected-values}

The {\em mean} or expected value of $g(X)$ is
\begin{equation}
  \label{eq:6}
  \Expect{g(X)} = \int g(x)dF_X(x) = \int g(x) dP(x) = \begin{cases}
    \int_{-\infty}^{\infty} g(x)p(x)dx & \mbox{if $X$ is continuous}\\
    \sum_j g(x_j)p(x_j) & \mbox{if $X$ is discrete.}
  \end{cases}
\end{equation}

Recall the following useful properties of expectation:

\begin{enumerate}
\item $\Expect{\sum^k_{j=1} c_jg_j(X)} = \sum^k_{j=1} c_j\Expect{g_j(X)}.$
\item If $X_1, \ldots , X_n$ are independent then
    $\Expect{ \prod_{i=1}^n X_i } = \prod_i \Expect{X_i}$.
\item We often write $\mu = \Expect{X}$.
\item $\sigma^2 =\Var{X}=\Expect{(X-\mu)^2}$is the Variance.
\item $\Var{X}=\Expect{X^2}-\mu^2.$
\item If $X_1, \ldots , X_n$ are independent then
  $\Var{\sum_{i=1}^n a_i X_i} = \sum_i a_i^2\Var{X_i}$
\item The covariance is $\Cov{X,Y}=\Expect{(X-\mu_X)(Y -\mu_Y)}=\Expect{XY}-\mu_X\mu_Y$
and the correlation is $\rho(X,Y)=\Cov{X,Y}/\sigma_X\sigma_Y$. Recall
that $−1\leq \rho (X,Y)\leq1$.
\end{enumerate}

The conditional expectation of $Y$ given $X$ is the random variable
$\Expect{Y|X}$ whose valeu, when $X=x$ is $\Expect{Y|X=x} = \int y p(y|x) dy$
where $p(y|x) = p(x,y)/p(x)$. The {\em Law of Total Expectation} or
{\em Law of Iterated Expectation:}
\begin{equation}
  \label{eq:8}
  \Expect{Y} = \Expect{\Expect{Y|X}} = \int \Expect{Y|X=x}p_x(x)dx.
\end{equation}


\begin{algorithm}[t!]
  \caption{Approximate Kalman filter\label{alg:kalman}}
  \begin{algorithmic}[1]
  \STATE {\bfseries Input:}
  % Produce minimum MSE estimates of
  % $w_i$ $i=1,\ldots,T$ using equation
  % \eqref{eq:state-space-model2}\\
  Initial state $w_0$, state variance $\mathbf{P}_0$,
    and sketching matrices $\Pi\in\R^{n\times m}$ and
    $\mathbf{R}\in\R^{p\times q}$.
  \STATE {\bfseries Compress:} $\tilde{\mathbf{H}}\rightarrow\Pi^\top
  \mathbf{H} \Pi$, $\tilde{\mathbf{G}}\rightarrow \mathbf{R}^\top
  \mathbf{G}\mathbf{R}$, $\tilde{\X}\rightarrow \Pi\X\mathbf{R}$,
  $\tilde{\mathbf{A}} = \mathbf{R}^\top \mathbf{A} \mathbf{R}$,
  $\tilde{\mathbf{P}}_0 = \mathbf{R}^\top \mathbf{P}_0\mathbf{R}$,
  $z_0=\mathbf{R}w_0$. \\ 
  \FOR{$i=1$ {\bfseries to} $T$}
    \STATE Compress the data $\tilde{Y}_i=\Pi Y_i$
    \STATE Run the standard Kalman filter to produce:
    $
    \tilde{z}_{i} \leftarrow
    \tilde{\mathbf{A}}\tilde{z}_{i-1}+\tilde{\mathbf{K}}_i(\tilde{Y}_i -
    \tilde{\X}\tilde{\mathbf{A}}\tilde{z}_{i-1}) 
    $
    \STATE Update 
    $\tilde{w}_i \leftarrow \mathbf{R}\tilde{z}_i$ and increment $\mathbf{P}_{i} = 
    \mathbf{R}\tilde{\mathbf{P}}_{i-1} \mathbf{R}^\top$\;
  \ENDFOR
  \STATE Return $w_i$ and $\mathbf{P}_i$, $i=1,\ldots,T$.
\end{algorithmic}
\end{algorithm}


\section{Important distributions}
\label{sec:import-distr}

\begin{description}
\item[Normal] $X\sim N(\mu,\sigma^2)$ if
  \begin{equation}
    \label{eq:7}
    p(x;\mu,\sigma^2) =
    \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left\{-\frac{1}{2\sigma^2}(x-\mu)^2\right\} 
  \end{equation}
\item[Multivariate normal] For $X\in \R^d$, $X\sim N_d(\mu, \Sigma)$ if
  \begin{equation}
    \label{eq:15}
    p(x;\mu,\Sigma) = \frac{1}{(2\pi)^{d/2}|\Sigma|^{1/2}}\exp\left\{-\frac{1}{2}(x-\mu)^\top\Sigma^{-1}(x-\mu)\right\} 
  \end{equation}
\item[Bernoulli] $X\sim Bernoulli(\theta)$ if $P(X=1)=\theta$ and
  $P(X=0) = 1-\theta$. Thus the pdf is
  \begin{equation}
    \label{eq:16}
    p(x;\theta) = \theta^x(1-\theta)^{1-x} I_{\{0,1\}}(x).
  \end{equation}
\item[Binomial] $X\sim Binomial(\theta)$ if
  \begin{equation}
    \label{eq:17}
    p(x;\theta) = P(X=x) = \binom{n}{x}\theta^x(1-\theta)^{n-x}I_{\{0,\ldots,n\}}(x).
  \end{equation}
\item[Uniform] $X\sim U(a,b)$ if $p(x) = I_{[a,b]}(x)/(b-a).$
\end{description}


Much of statistical machine learning is concerned with showing
asymptotic, or better yet, finite sample properties of computational
methods. We want to know whether our methods will perform well, and if
so how well will they perform relative to other methods. For that, we
need to discuss some useful results from probability theory. First,
we'll review the convergence of random variables.

\section{Convergence}
\label{sec:convergence}

Let $X_1,X_2,\ldots$ be a sequence of random variables, and let $X$ be
another random variable with distribution $P$. Let $F_n$ be the cdf of $X_n$ and let $F$ be
the cdf of $X$.
\begin{enumerate}
\item $X_n$ converges {\em almost surely} to $X$, $X_n\cas
  X$, if for every $\epsilon>0$,
  \begin{equation}
    \label{eq:1}
    P\left( \lim_{n\rightarrow\infty} |X_n-X| < \epsilon\right) =
    1. \footnote{The absolute value here can be replaced by any
      appropriate distance.}
  \end{equation}
\item $X_n$ converges {\em in probability} to $X$, $X_n\cprob
  X$, if for every $\epsilon>0$,
  \begin{equation}
    \label{eq:2}
   \lim_{n\rightarrow\infty} P\left(|X_n-X| < \epsilon\right) = 1. 
  \end{equation}
\item $X_n$ converges {\em in $L_p$} to $X$, $X_n\clp
  X$, if 
  \begin{equation}
   \lim_{n\rightarrow\infty} \int |X_n- X|^p dP =
   \lim_{n\rightarrow\infty} \Expect{|X_n-X|^p} = 0.
  \end{equation}
\item $X_n$ converges {\em in distribution} to $X$, $X_n \cdist
  X$, if 
  \begin{equation}
    lim_{n\rightarrow\infty} F_n(t) = F(t)
  \end{equation}
for all $t$ for which $F$ is continuous.
\end{enumerate}


\begin{example}
  This example shows that convergence in probability does not imply
  almost sure convergence. Let $S = [0, 1]$. Let $P$ be uniform on $[0,
  1]$. We draw $S ∼ P$ . Let $X(s) = s$ and let
  \begin{align*}
    X_1 &= s + I_{[0,1]}(s) & X_2 &= s + I_{[0,1/2]}(s) & X_3 &= s +
    I_{[1/2,1]}(s)\\
    X_4 &= s + I_{[0,1/3]}(s) & X_5 &= s + I_{[1/3,2/3]}(s) & X_6 &= s
    + I_{[2/3,1]}(s) 
  \end{align*}
etc. Then $X_n\cprob$ since $P(|X_n-X|>\epsilon)$ is equal to
the probability of an interval of $s$ values whose length is going to
zero. However, for every $s$, $X_n(s)$ alternates between the values
$s$ and $s+1$ infinitely often, so this convergence does not occur
almost surely.
\end{example}

\begin{theorem}
  \label{thm:convergence-1}
  The following relationships hold:
  \begin{enumerate}
  \item [(a)] $X_n\clp X$ implies that $X_n \cprob X$.
  \item [(b)]$X_n\cprob X$ implies that $X_n \cdist
    X$.
  \item [(c)] If $X_n\cdist X$ and if $P(X =c)=1$ for some
    real number $c$, then $X_n\cprob X$.
  \item [(d)]$X_n\cas X$ implies that $X_n \cprob X$.
  \end{enumerate}
\end{theorem}

\begin{theorem}
  \label{thm:convergence-2}
  Let $X_n,X,Y_n,Y$ be random variables. Let $g$ be a continuous
  function. Let $c$ be a constant.
  \begin{enumerate}
  \item [(a)] If $X_n\cprob X$ and $Y_n\cprob Y$, then
    $X_n+Y_n\cprob X+Y$.
  \item [(b)] If $X_n\clp X$ and $Y_n\clp Y$,
    then $X_n+Y_n\clp X+Y$.
  \item [(c)] If $X_n\cdist X$ and $Y_n\cdist c$,
    then $X_n+Y_n\cdist X+c$.
  \item [(d)] If $X_n\cprob X$ and $Y_n\cprob Y$, then
    $X_nY_n\cprob XY$.
  \item [(e)] If $X_n\cdist X$ and $Y_n\cdist c$, then
    $X_nY_n\cdist cX$.
  \item [(f)] If $X_n\xrightarrow{\mbox{converges somehow}} X$, then
    $g(X_n)\xrightarrow{\mbox{converges the same}} g(X)$.
  \end{enumerate}
  \begin{itemize}
  \item Parts (c) and (e) are known as {\em Slutsky's theorem}.
  \item Part (f) is known as {\em The continuous mapping theorem}.
  \end{itemize}
\end{theorem}

\section{LLNs and CLT}
\label{sec:llns-clt}

\begin{theorem}[Weak law of large numbers]
  \label{thm:llns-clt-1}
  Let $X_1, X_2,\ldots$ be independent random variables, each with
  finite mean and variance. Define $S_n = X_1 + \cdots + X_n$. Then
  $\frac{1}{n}(S_n-\Expect{S_n}) \cprob 0$.
\end{theorem}

\begin{theorem}[Strong law of large numbers]
  \label{thm:llns-clt-2}
  Let $X_1, X_2,\ldots$ be iid random variables with common mean $m$. Define $S_n = X_1 + \cdots + X_n$. Then
  $S_n/n \cas m$.
\end{theorem}

The laws of large numbers tell us that the probability mass of an
average of random variables ``piles up'' near its expectation. In just
a minute, we will see even more: how fast this piling occurs. But
first we should talk about the distribution of the average.

\begin{theorem}[Central limit theorem]
  \label{thm:llns-clt-3}
  Let $X_1, X_2,\ldots$ be iid with mean $\mu$ and variance
  $\sigma^2<\infty$. Let $\bar{X}_n = \frac{1}{n}\sum_{i=1}^n X_i$. Then,
  \begin{equation}
    \label{eq:3}
    Z_n := \frac{\bar{X}_n - \mu}{\sqrt{\Var{\bar{X}_n}}} =
    \frac{\sqrt{n}(\bar{X}_n-\mu)}{\sigma}\cdist Z,
  \end{equation}
where $Z\sim N(0,1)$. 
\end{theorem}


\bibliographystyle{scribebibsty}
\bibliography{s782references}

\end{document}
